### model
model: /nas_data/userdata/randy/models/Qwen2.5-14B-Instruct

### method
stage: pt
train_type: lora
tuner_backend: peft
lora_rank: 64
lora_alpha: 128
lora_dropout: 0.05
deepspeed: zero2

### dataset
dataset_info: /nas_data/userdata/randy/projects/ms-swift/randy/dataset_info.json
dataset: semi-misc,semi-book-paper,cxmt-private,cxmt-dict-semi,cxmt-cptest-videos,cxmt-lms-videos
packing: true
max_length: 2048
enable_cache: true
dataset_num_proc: 16
truncation_strategy: delete

### output
output_dir: /nas_data/userdata/randy/models/cxmt/pt/lora
logging_steps: 10
logging_first_step: true
save_strategy: steps
save_steps: 100
save_total_limit: 10
report_to: tensorboard

### train
per_device_train_batch_size: 1
gradient_accumulation_steps: 4
warmup_ratio: 0.05
learning_rate: 1e-4
num_train_epochs: 3.0
lr_scheduler_type: cosine
attn_impl: flash_attn
use_liger: true

### eval
per_device_eval_batch_size: 1
split_dataset_ratio: 0.01
eval_strategy: steps
eval_steps: 100
